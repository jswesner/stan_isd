---
title: "Bayesian hierarchical modeling of size spectra"
fontsize: 12pt
header-includes:
- \usepackage{setspace}\doublespacing
- \usepackage{amsmath}
- \usepackage{lineno}
- \linenumbers
- \usepackage{fontspec}
- \setmainfont{Times New Roman}
- \usepackage{placeins}
output:
  word_document: default
  pdf_document:
    latex_engine: xelatex
    keep_tex: yes
bibliography: refs.bib
link-citations: no
link-color: grey
csl: oikos.csl
---

*Jeff S. Wesner*^1^, *Justin P.F. Pomeranz*^2^, *James R. Junker*^3,4^, *Vojsava Gjoni*^1^

^1^University of South Dakota, Department of Biology, Vermillion, SD 57069

^2^Colorado Mesa University, Environmental Science and Technology, Grand Junction, CO 81501

^3^Great Lakes Research Center, Michigan Technological University, Houghton, MI 49931

^4^Louisiana Universities Marine Consortium, Chauvin, LA 70344

Corresponding Author: [Jeff.Wesner\@usd.edu](mailto:Jeff.Wesner@usd.edu){.email}

Running Head: Bayesian Size Spectra

*Data Archiving Statement*

All data, R code, and Stan code are available at <https://github.com/jswesner/stan_isd> (to be permanently archived at Zenodo upon acceptance). Body size data from the International Benthic Trawl Surveys was retrieved from <https://github.com/andrew-edwards/sizeSpectra/tree/master/data>.

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(brms)
library(rstan)
library(stringi)
```

\newpage

# Abstract

A fundamental pattern in ecology is that smaller organisms are more abundant than larger organisms. This pattern is known as the individual size distribution (ISD), which is the frequency of all individual sizes in an ecosystem, regardless of taxon. The ISD is described by power law distribution with the form $f(x) = Cx^{\lambda}$, and a major goal of size spectra analyses is to estimate the ISD parameter $\lambda$. However, while numerous methods have been developed to do this, they have focused almost exclusively on estimating $\lambda$ from single samples. Here, we develop an extension of the truncated Pareto distribution within the probabilistic modeling language Stan. We use it to estimate multiple ISD parameters simultaneously with a hierarchical modeling approach. The most important result is the ability to examine hypotheses related to size spectra, including the assessment of fixed and random effects, within a single Bayesian generalized (non)-linear mixed model. While the example here using size spectra, the technique can also be generalized to any data that follows a power law distribution.

Keywords: *Bayesian, body size spectra, hierarchical, Pareto, power law, Stan*

\newpage

# Introduction

In any ecosystem, large individuals are typically more rare than small individuals. This fundamental feature of ecosystems leads to a remarkably common pattern in which relative abundance declines with individual body size, generating the individual size distribution (ISD), also called the community size spectrum [@sprules1983; @white2008]. Understanding how body sizes are distributed has been a focus in ecology for over a century [@peters1983effect], in part because they represent an ataxic approach that reflects fundamental measures of ecosystem structure and function, such as trophic transfer efficiency. [@kerr2001; @white2007; @perkins2019]. Individual size distributions are also predicted as a result of physiological limits associated with body size, thereby emerging from predictions of metabolic theory and energetic equivalence [@brown2004].

More formally, the ISD is a frequency distribution that can be approximated by a bounded power law with a single free parameter $\lambda$, corresponding to the following probability density function [@edwards2020]:

```{=tex}
\begin{equation}
f(x) = Cx^\lambda, x_{min} \le x \ge x_{max}
\end{equation}
```
where $x$ is the body size (e.g., mass or volume) of an individual regardless of taxon, $x_{min}$ is the smallest individual attainable and $x_{max}$ is the largest possible individual [@white2008]. $C$ is a constant equal to:

```{=tex}
\begin{equation}
 C = \begin{cases}\frac{\lambda + 1}{{x_{max}^{\lambda+1}} - {x_{min}^{\lambda+1}}}, \lambda \neq-1 \\
\frac{1}{{logx_{max}} - {logx_{min}}}, \lambda = -1\end{cases}
\end{equation}
```
This model is also known as the bounded power law or truncated Pareto distribution. The terms "bounded" or "truncated" refer to the limits of $x_{min}$ and $x_{max}$, which represent the minimum and maximum attainable body size values [@white2008]. In practice, values of $x_{min}$ and $x_{max}$ often come from the minimum and maximum body sizes in a data set or are estimated statistically [@white2008; @edwards2017].

A compelling feature of size spectra is that $\lambda$ may vary little across ecosystems as a result of physiological constraints that lead to size-abundance patterns more broadly. Metabolic scaling theory predicts $\lambda + 1 = \frac{log10\alpha}{log10\beta} - 3/4$, where $\alpha$ is trophic transfer efficiency in the food web and $\beta$ is the mean predator-prey mass ratio [@reuman2008three]. The value of $-3/4$ is the predicted scaling exponent of log abundance and log mass [@damuth1981population; @peters1983effect]. It is the reciprocal of scaling coefficient of metabolic rate and mass (0.75) [@brown2004] and as a result, values of $\lambda + 1$ have been used to estimate metabolic scaling across ecosystems [@reuman2008three; @perkins2018; @perkins2019]. Because $\frac{log10\alpha}{log10\beta}$ is typically \<\<0.01, this implies that a $\lambda$ values of \~-1.75 represent a reasonable first guess of expected ISD exponents, with values of ranging from -1.2 to -2 often appearing in the literature [@andersen2006; @blanchard2009; @pomeranz2020].

Whether $\lambda$ represents a fixed or variable value is debated, but it often varies among samples and ecosystems [@blanchard2009; @pomeranz2020; @perkins2018]. It is often described by its "steepness", with more negative values (i.e., "steeper") indicating lower abundance of large relative to small individuals, and vice versa. These patterns of size frequency are an emergent property of demographic processes (e.g., age-dependent mortality), ecological interactions (e.g., size-structured predation, trophic transfer efficiency), and physiological constraints (e.g., size-dependent metabolic rates) [@muller2006comparing; @andersen2006; @white2008]. As a result, variation in $\lambda$ across ecosystems or across time can indicate fundamental shifts in community structure or ecosystem functioning. For example, overfishing in marine communities has been detected using size spectra in which $\lambda$ was steeper than expected, indicating fewer large fish than expected [@jennings_fish_2004]. Shifts in $\lambda$ have also been used to document responses to acid mine drainage in streams [@pomeranz2019; @pomeranz2020a], land use [@martinez2016], resource subsidies [@perkins2018], and temperature [@ogorman2017; @pomeranz2022].

Given the ecological information it conveys, the data required to estimate size spectra are deceptively simple; only a single column of data are needed, in which each data point is a single measure of the body size of an individual. As long as the body sizes are collected systematically and without bias towards certain taxa or phenotypes, there is no need to know any more ecological information about the data points (e.g., taxon, trophic position, age, abundance). However, despite the simple data requirement, the statistical models used to estimate $\lambda$ are diverse. @edwards2017 documented 8 different analytical methods. Six involved binning, in which the body sizes are grouped into size bins (e.g., 2-49 mg, 50-150 mg, etc.) and then counted, generating values for abundance within each size bin. When both axes are log-transformed, binning allows $\lambda$ to be estimated using simple linear regression. Unfortunately, the binning process also removes most of the variation in the data, collapsing information about 1000's of individuals into just 6 or so bins. Doing so can lead to the wrong values of $\lambda$, sometimes drastically so [@goldstein2004problems; @white2008; @pomeranz2023detecting].

An improved alternative to binning and linear regression is to fit the body size data to a power law probability distribution [@white2008; @edwards2017; @edwards2020]. This method uses all raw data observations directly to estimate $\lambda$, typically using the maximum likelihood estimation method [@edwards2017]. In addition to estimating size spectra of single samples, ecologists have used this method to examine how $\lambda$ varies across environmental gradients [@perkins2019; @pomeranz2022]. However, these analyses typically proceed in two steps. First, $\lambda$ estimates are obtained individually from each collection (e.g., each site or year, etc.). Second, these estimates are used as response variables in a linear model to examine how they relate to corresponding predictor variables [@edwards2020]. A downside to this approach is that it treats body sizes (and subsequent $\lambda$'s) as independent samples, even if they come from the same site or time. It also removes information on sample size (number of individuals) used to derive $\lambda$. As a result, the approach not only separates the data generation model from the predictor variables, but is also unable to take advantage of partial pooling during model fitting.

Here, we develop a Bayesian model that uses the truncated Pareto distribution to estimate $\lambda$ in response to both fixed and random predictor variables. The model extends the maximum likelihood approach developed by @edwards2020 and allows for a flexible hierarchical structure, including partial pooling, within the modeling language Stan [@rstan2022].

# Methods

## Translating to Stan

We first translated the probability density function described by @edwards2020 into Stan by converting it to the log probability density function (lpdf). Stan is a probabilistic modeling language that is capable of fitting complex models, including those with custom lpdf's. The resulting lpdf is given as

```{=tex}
\begin{equation}
 lpdf = \begin{cases}\text{log}\frac{\lambda + 1}{{x_{max}^{\lambda+1}} - {x_{min}^{\lambda+1}}} + \lambda\text{log}x, \lambda \neq-1 \\
\text{-log}({{\text{log}x_{max}} - {\text{log}x_{min}}}) -\text{log}x, \lambda = -1\end{cases}
\end{equation}
```
with all variables as described above. We call this the $paretocustom$ distribution, which we can now use to estimate $\lambda$ of a given data set. For example, an intercept-only model would look like this:

```{=tex}
\begin{equation}x_i \sim paretocustom(\lambda, x_{min}, x_{max})$$ $$\lambda = \alpha$$ $$\alpha \sim Normal(\mu, \sigma)\end{equation}
```
where $x_i$ is the $i$th individual body size, $\lambda$ is the size spectrum parameter (also referred to as the exponent), $x_{min}$ and $x_{max}$ are as defined above, and $\alpha$ is the intercept with a prior probability distribution. In this case, we specified a Normal prior since $\lambda$ is continuous and can be positive or negative, but this can be changed as needed.

The simple model above can be expanded to a generalized linear mixed model by including fixed predictors ($\boldsymbol\beta \textbf{X}$) and/or varying intercepts ($\alpha_{[x]}$):

```{=tex}
\begin{equation}x_{ij} \sim paretocustom(\lambda_j, x_{min, j}, x_{max, j})$$ $$\lambda = \alpha + \boldsymbol\beta \textbf{X} + \alpha_{[j]} + \alpha_{[x]}$$ $$\alpha \sim Normal(\mu_{\alpha}, \sigma_{\alpha})$$ $$\beta \sim Normal(\mu_{\beta},\sigma_{\beta})$$ $$\alpha_{[j]} \sim Normal(0, \sigma_{[j]})$$ $$\sigma_{[j]} \sim Exponential(\phi)$$ $$\alpha_{[x]} \sim Normal(0, \sigma_{[x]})$$ $$\sigma_{[x]} \sim Exponential(\phi)\end{equation}
```
with one or more $\beta$ regression parameters, represented by the vector $\boldsymbol\beta$, for one or more fixed predictors $\textbf{X}$, and one or more varying intercepts $\alpha_x$. We specify $\alpha_{j}$ separately because it is needed to account for the non-independence of body sizes. In other words, each body size $x_i$ is clustered within each site and so they are not independent and identically distributed. The addition of a varying intercept for each sample accounts for this non-independence. Prior distributions are given as $Normal$ for the parameters and varying intercept and $Exponential$ for $\sigma{[x]}$, but these can also be changed as needed.

The model above assumes that each body size $x$ represents a single individual such that the data set might have many repeats for individuals of the same size (e.g., $x$ = {0.2, 0.2, 0.2, 0.4, 0.4, 0.5, 9.8}). However, when individual body sizes are repeated in a data set, they are often accompanied by a count or density, such that the data set above might instead consist of two columns with $x$ = {0.2, 0.4, 0.5, 9.8} and $counts$ = {3, 2, 1, 1}. To analyze this more compact data set, @edwards2020 developed a modification of the log probability density function to include $counts$:

```{=tex}
\begin{equation}
 lpdf = \begin{cases}\textit{counts}(\text{log}\frac{\lambda + 1}{{x_{max}^{\lambda+1}} - {x_{min}^{\lambda+1}}} + \lambda\text{log}x), \lambda \neq-1 \\
\textit{counts}(
\text{-log}({{\text{log}x_{max}} - {\text{log}x_{min}}}) -\text{log}x, \lambda = -1\end{cases}.
\end{equation}
```
We refer to this as $paretocounts$, such that the model can be fit by using

```{=tex}
\begin{equation}x_i\sim paretocounts(\lambda, x_{min}, x_{max}, counts)$$ $$\lambda = [\text{linear or non-linear model}] \text{ and}$$ $$\text{[priors]}.\end{equation}
```
Aside from adding $counts$, the model is the same as presented above. These models ($paretocustom$ and $paretocounts$) allow us to test how the size distribution parameter, $\lambda$, varies in response to continuous or categorical predictors and to include hierarchical structure as needed.

## Testing the models

The $paretocustom$ and $paretocounts$ lpdfs give the same results, differing only in how the data are aggregated. For simplicity, we demonstrate model performance here for the $paretocounts$ distribution, since the empirical data we used (see *Case Study* below) contains counts of individual body sizes. First, we tested for parameter recovery using data simulated from a bounded power law with known values of $\lambda$. Second, we fit the model to fisheries trawl data presented in @edwards2020 to estimate the hypothesis that $\lambda$ declines over time.

## Parameter recovery from simulated data

To ensure that the models could recover known parameter values, we simulated ten data sets from a bounded power law using the inverse cumulative density function:

```{=tex}
\begin{equation}
x_i = (\text{u}_ix_{max}^{(\lambda+1)} +  (1-\text{u}_i)  x_{min}^{(\lambda+1)} ) ^ {\frac{1}{(\lambda+1)}}
\end{equation}
```
where $x_i$ is the individual body size from the $i$th simulation, $u_i$ is a unique draw from a $Uniform(0,1)$ distribution, and all other variables are the same as defined above. We set $x_{min}$ = 1, $x_{max}$ = 1000, and simulated $i$ = 1000 values from each of 10 $\lambda$'s ranging from -2.2 to -1.2. To generate $counts$, we rounded each simulated value to the nearest 0.001 and then tallied them.

We estimated the ten $\lambda$ values in two ways. First, we fit a separate intercept-only model to each of the ten data sets. Second, we fit a varying intercept model (Gelman et al. 2014). The structure of this model is $\lambda = \alpha + \alpha_{[group]}$ where each group represents an offset from the mean value of lambda.

Finally, we simulated data for a regression model with a single continuous predictor and a varying intercept: $\lambda = \alpha + \beta x + \alpha_{[group]}$, where $\alpha$ = -1.5, $\beta$ = -0.1, and $\sigma_{group}$ = 0.3. The predictor variable $x$ was a continuous predictor. Using these parameters, we simulated 18 $\lambda$'s, with each $\lambda$ coming from one of three $x$-values (-2, 0, 2), nested within 3 groups with each replicated twice. From each $\lambda$, we simulated 1000 individuals using the procedure above, with $x_{min}$ = 1 and $x_{max}$ = 1000. Using those 18,000 simulated body sizes (1000 sizes simulated from 18 $\lambda$'s), we fit a $paretocounts$ regression model 40 times to measure variation in parameter recovery among model runs.

## Sample Size

We examined sensitivity to sample size (number of individual body sizes) across three $\lambda$ values (-2, -1.6, -1.2). For each $\lambda$, we varied the number of simulated individuals from 2 to 2048, representing a $2^n$ sequence with $n$ ranging from 1 to 11. Each of the 11 densities was replicated 10 times resulting in 110 datasets of individual body sizes. We fit each data set using separate intercept-only $paretocounts$ models and then plotted the resulting $\lambda$ values as a function of sample size.

## Case Studies

To examine model performance on empirical data, we re-ran a previously published analysis from Edwards et al. (2020). In Edwards' study, size spectra parameters were first estimated separately for each sample using maximum likelihood. Then the modeled parameters were used as response variables in linear regression models. The goal was to test for linear changes in size spectra over three decades using bi-yearly size data of marine fishes collected from the International Benthic Trawl Survey (IBTS). The data set and original model results are available in the `sizeSpectra` package [@edwards2017]. We tested the same hypothesis as @edwards2020, but instead of using a two-step process we fit a single model using the $paretocounts$ lpdf.

## Model Fitting

We fit each of the above models in `rstan` [@rstan2022] using 2 chains each with 1000 iterations. All models converged with $R_{hat}$'s \<1.01. If a known parameter value fell inside the 95% Credible Intervals, we considered parameter recovery successful. For the replicated regression model, we also tallied the number of times that the known value fell outside of the 95% CrI. Assessments of prior influence and model checking are available in Appendix S1.

## Data Availability Statement

All data, R code, and Stan code are available at <https://github.com/jswesner/stan_isd> (to be permanently archived on acceptance).

# Results

## Parameter Recovery

For models fit to simulated individual data sets, all 95% credible intervals included the true value of $\lambda$ and posterior medians were no more than 0.05 units away from the true value (Table 1). Similarly, when the same data set was fit using a varying intercepts model, the posterior median intercept $\alpha$ and group standard deviation $\sigma_{group}$ were nearly identical to the true values (Table 1). Using the varying intercept model to estimate group specific means yielded similar results as using separate models per group (Figure 1a), demonstrating that a single model can be used to estimate multiple size spectra. The change from "shallow" to "steep" size spectra is also evident in plots of the proportion of values $\ge x$ (i.e., $f(x)$ from Eq. 1) (Figure 1b-d).

We also recovered regression parameters ($\alpha$, $\beta$) along with the group-level standard deviation ($\sigma_{group}$ (Figure 2). Thirty-seven of the 40 models converged. Of those 37 models the true value fell outside of the 95% CrI once for $\alpha$ and $\sigma_{group}$ and three times for $\beta$ (Figure 2). Averaging the deviations (posterior median minus the true value) among the replicates indicated no bias in the modeled estimates (mean bias $\pm$ sd: $\alpha$ = -0.01 $\pm$ 0.05, $\beta$ = 0001 $\pm$ 0.004, $\sigma_{group}$ = 0.02 $\pm$ 0.05).

## Sample Size

Variation in modeled estimates was high for samples containing less than 100 individual (Figure 3). For example, when the true $\lambda$ value was -2, samples with just 8 individuals yielded estimates ranging from -2.7 to -1.7. By contrast, all samples with more than 300 individuals captured the true $\lambda$ with less than 0.1 unit of error (Figure 3).

## Case Study

Using IBTS data [@edwards2017] with a Bayesian hierarchical regression, we found a negative trend over time. The ISD parameter of IBTS trawl data declined by \~0.001 units per year, but with a 95% CrI ranging from -0.005 to 0.002. These values were nearly identical to those reported by Edwards et al. (2020) using a two-step approach (Table 2). An advantage of fitting the model in a single Bayesian hierarchical framework is that estimates for individual groups are pulled toward the mean via partial pooling. This is apparent in comparing the unpooled MLE estimates (Figure 4a) to the partially pooled Bayesian estimates in each year (Figure 4b).

## Discussion

The most important result of this work is the ability to analyze ISD parameters using fixed and random predictors in a hierarchical model. Our approach allows ecologists to test hypotheses about size spectra while avoiding the pitfalls of binning, which loses information and can lead to biased estimates of $\lambda$ [@white2008]. Maximum likelihood solves this problem by directly estimating the ISD, but testing hypotheses with maximum likelihood is often done with a two-step process in which $\lambda$ is estimated individually for each sample and the results are then used as response variables in linear or non-linear models [@edwards2020]. Our approach merges these steps, allowing for the incorporation of prior probabilities and hierarchical structure.

The ability to incorporate prior information using Bayesian updating has two practical advantages over the two-step process described above. First, adding informative prior distributions can improve model fit by limiting the MCMC sampler to reasonable sampling space. In other words it would not be sensible to estimate the probability that $\lambda$ is -1,234 or -9. Without informative priors, those values (and more extreme values) are considered equally likely and hence waste much of the algorithm's sampling effort on unlikely values (e.g., [@wesner2021]).

Second, and most importantly, ecologists have much prior information on the values that $\lambda$ can take. For example, global analysis of phytoplankton reveals values of -1.75, consistent with prediction based on sub-linear scaling of metabolic rate with mass of -3/4 [@perkins2019]. Alternatively, Sheldon's conjecture suggests that $\lambda$ is -2.05 (Andersen et al. 2006), a value reflecting isometric scaling of metabolic rate and mass, with support in pelagic marine food webs [@andersen2006]. However, benthic marine systems typically have shallower exponents (e.g., $\sim$ -1.4; @blanchard2009), similar to those in some freshwater stream ecosystems (-[@pomeranz2022]. While the causes of these deviations from theoretical predictions are debated, it is clear that values of $\lambda$ are restricted to a relatively narrow range between about -2.05 and -1.2. But this restriction is not known to the truncated Pareto, which has no natural lower or upper bounds on $\lambda$ [@white2008]. As a result, a prior that places most of its probability mass on these values (e.g., $Normal(-1.75, 0.2)$ seems appropriate. Such a continuous prior does not prevent findings of larger or smaller $\lambda$, but instead places properly weighted skepticism on such values.

Similar to priors, partial pooling from varying intercepts provides additional benefits, allowing for the incorporation of hierarchical structure and pulling $\lambda$ estimates towards the global mean [@gelman2005; @qian2010application]. In the examples shown here, the amount of pooling is relatively small because the sample sizes are large (\>1000 individuals). However, the primary benefit of pooling (both from varying effects and skeptical priors) is in prediction [@gelman2005; @hobbs2015]. This becomes especially important when models are used to forecast future ecosystem conditions. Forecasts are becoming more common in ecology [@dietze2018iterative] and are likely to be easier to test with modern long-term data sets like NEON (National Ecological Observatory Network) in which body size samples will be collected at the continental scale over at least the next 20 years [@kuhlman2016]. In addition, because the effects of priors and pooling increase with smaller samples sizes, varying intercepts are likely to be particularly helpful for small samples. In other words, priors and partial pooling contain built-in skepticism of extreme values, ensuring the maxim that "extraordinary claims require extraordinary evidence".

One major drawback to the Bayesian modeling framework here is time. Bayesian models of even minimal complexity must be estimated with Markov Chain Monte Carlo techniques. In this study, we used the No U-Turn sampling (NUTS) algorithm via `rstan` [@rstan2022]. Stan can be substantially faster than other commonly used programs such as JAGS and WinBUGS, which rely on Gibbs sampling. For example, Stan is 10 to 1000 times more efficient than JAGS or WinBUGS, with the differences becoming greater as model complexity increases [@monnahan2017]. In the current study, intercept-only models for individual samples with $\sim$ 300 to 1500 individuals could be fit quickly (\<2 seconds total run time (warm-up + sampling on a Lenovo T490 with 16GB RAM)) with as little as 1000 iterations and two chains. However, the IBTS regression models took \>2 hours to run with the same iterations and chains. These times include the fact that our models used several optimization techniques, such as informative priors, standardized predictors, and non-centered parameterization, each of which are known to improve convergence and reduce sampling time [@mcelreath2020]. But if Bayesian inference is desired, these run-times may be worth the wait. In addition, they are certain to become faster with the refinement of existing algorithms and the introduction of newer ones like Microcanonical HMC [@robnik2022].

Body size distributions in ecosystems have been studied for decades, yet comprehensive analytical approaches to testing these hypotheses are lacking. We present a single analytical approach that takes advantage of the underlying data structures of individual body sizes (Pareto distributions) while placing them in a generalized (Non)-linear hierarchical modeling framework. We hope that ecologists will adopt and improve on the models here to critically examine hypotheses of size spectra or other power-law distributed data.

# Acknowledgements

This material is based upon work supported by the National Science Foundation under Grant Nos. 2106067 to JSW and 2106068 to JRJ. We thank Professor Yuhlong Lio for statistical and mathematical advice and Edwards et al. (2017) and (2020) for placing their code and data in easily accessible repositories.

# References

::: {#refs}
:::

\newpage

# Tables

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(here)
library(tidyverse)
parameter_recovery = read_csv(here("tables/parameter_recovery.csv")) %>%
  mutate(across(where(is.numeric), round, 2))

knitr::kable(parameter_recovery, align = 'llrrrr',
                  col.names = c("Model", "Parameter", "True Value",
                                "q2.5", "q50", "q97.5"),
                  caption = "Table 1. Parameter recovery of the same data using two approaches. First, ten separate models individually recapture known lambda values. Second, the same ten data sets are estimated in a single hierarchical model. The true values are compared to the posterior median and 95% Credible Intervals.")
```

\newpage

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

mle_bayes_table = read_csv(here("tables/bayes_mle_regression_table.csv"))

knitr::kable(mle_bayes_table,
                  col.names = c("Model", "Mean", "q2.5", "q97.5"),
                  caption = "Table 2. Slope values from a regression testing the relationship between the ISD exponent and year for IBTS trawl data (Edwards et al. 2020). The values are derived using the Bayesian hierarchical model presented here or from the maximum likelihood approach described in Edwards et al. (2020).")

```

\newpage

# Figure Captions

Figure 1. a) Modeled estimates (median +/- 95% Credible Intervals) of $\lambda$ using either 10 separate models or a single model with ten varying intercepts. c-d) Fit of ISD relationships at 3 values of $\lambda$. Dots are raw data, lines are posterior medians, and shading is the 95% credible interval. Fits are from separate models.

Figure 2. Posterior distributions of n = 40 modeled estimates of alpha, beta, and sigma_group for a linear regression estimating the size spectrum exponent as a function of a continuous predictor. All data were simulated. Gray densities indicate that the 95% CrI contains the true value, while black densities indicate the true values fall outside of the CrI. The vertical lines indicate true values.

Figure 3. Estimates of $\lambda$B across 11 different sample sizes (ranging from 2 to 2048 individuals) and three different true $\lambda$'s (-2, -1.6, -1.2). Ten separate models were fit for each of the 11 sample sizes. The horizontal lines show the true value of $\lambda$.

Figure 4. Regression results from a) Edwards et al. (2020) using maximum likelihood and linear regression (two steps) and b) the Bayesian model with varying intercepts. In a) the points represent maximum likelihood estimates calculated separately for each year. In b) they represent hierarchical varying intercepts calculated from the model.
